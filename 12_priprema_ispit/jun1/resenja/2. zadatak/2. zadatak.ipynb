{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. zadatak (5 poena)**\n",
    "<br>\n",
    "\n",
    "Korišćenjem Keras biblioteke napraviti neuronsku mrežu koja će se koristiti u klasifikaciji iris cvetova. \n",
    "<br>\n",
    "\n",
    "a) Pročitati podatke koji se nalaze u iris skupu *sklearn* paketa, a zatim preduzeti sve neophodne pripremne korake i podeliti skup podataka na skup za treniranje i skup za testiranje u razmeri 2:1. Za $random\\_state$ parametar uzeti vrednost 7. \n",
    "<br>\n",
    "\n",
    "b) Napraviti neuronsku mrežu koja se sastoji od: \n",
    "* ulaznog sloja sa brojem neurona koji odgovara broju atributa ulaznog skupa\n",
    "* gustog sloja koji sadži 16 neurona sa sigmoidnom aktivacijom  \n",
    "* izlaznog sloja sa brojem neurona koji odgovara broju različitih kategorija cvetova; aktivacija ovog sloja je meki maksimum \n",
    "\n",
    "<br>\n",
    "\n",
    "Mreži pridružiti Adam optimizator, kategoričku unakrsnu entropiju kao funkciju gubitka i tačnost kao metriku.\n",
    "<br>\n",
    "\n",
    "c) Nacrtati grafik zavisnosti tačnosti klasifikatora u odnosu na broj epoha u toku treniranja mreže koršćenjem paketa veličine  8. Za broj epoha uzeti 40.  \n",
    "\n",
    "<br>\n",
    "\n",
    "d) Dati ocenu klasifikatora na skupu za testiranje. \n",
    "\n",
    "<br>\n",
    "e) Kakva je ocena klasifikatora na skupu za testiranje ukoliko se prilikom učenja koristi  regularizaciona tehnika ranog zaustavljanja sa *patience* parametrom sa vrednošću 4?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import losses\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = load_iris()['data']\n",
    "target = load_iris()['target']\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class_0</th>\n",
       "      <th>Class_1</th>\n",
       "      <th>Class_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class_0  Class_1  Class_2\n",
       "0        1        0        0\n",
       "1        1        0        0\n",
       "2        1        0        0\n",
       "3        1        0        0\n",
       "4        1        0        0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(target, prefix='Class', drop_first=False)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=load_iris()['feature_names']\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test=model_selection.train_test_split(x, y, test_size=0.33, random_state=7, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = len(features)\n",
    "output_size = len(np.unique(target))\n",
    "output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16,input_dim=input_size,activation='sigmoid'))\n",
    "model.add(Dense(output_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=losses.categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 1.1613 - acc: 0.3300\n",
      "Epoch 2/40\n",
      "100/100 [==============================] - 0s 316us/step - loss: 1.1124 - acc: 0.3300\n",
      "Epoch 3/40\n",
      "100/100 [==============================] - 0s 276us/step - loss: 1.0736 - acc: 0.3300\n",
      "Epoch 4/40\n",
      "100/100 [==============================] - 0s 413us/step - loss: 1.0370 - acc: 0.3800\n",
      "Epoch 5/40\n",
      "100/100 [==============================] - 0s 280us/step - loss: 1.0057 - acc: 0.6200\n",
      "Epoch 6/40\n",
      "100/100 [==============================] - 0s 292us/step - loss: 0.9794 - acc: 0.6500\n",
      "Epoch 7/40\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.9535 - acc: 0.6500\n",
      "Epoch 8/40\n",
      "100/100 [==============================] - 0s 351us/step - loss: 0.9289 - acc: 0.6800\n",
      "Epoch 9/40\n",
      "100/100 [==============================] - 0s 285us/step - loss: 0.9057 - acc: 0.7000\n",
      "Epoch 10/40\n",
      "100/100 [==============================] - 0s 213us/step - loss: 0.8835 - acc: 0.7500\n",
      "Epoch 11/40\n",
      "100/100 [==============================] - 0s 221us/step - loss: 0.8617 - acc: 0.7800\n",
      "Epoch 12/40\n",
      "100/100 [==============================] - 0s 390us/step - loss: 0.8399 - acc: 0.8000\n",
      "Epoch 13/40\n",
      "100/100 [==============================] - 0s 275us/step - loss: 0.8194 - acc: 0.8300\n",
      "Epoch 14/40\n",
      "100/100 [==============================] - 0s 250us/step - loss: 0.7990 - acc: 0.8500\n",
      "Epoch 15/40\n",
      "100/100 [==============================] - 0s 355us/step - loss: 0.7791 - acc: 0.8500\n",
      "Epoch 16/40\n",
      "100/100 [==============================] - 0s 326us/step - loss: 0.7605 - acc: 0.8400\n",
      "Epoch 17/40\n",
      "100/100 [==============================] - 0s 240us/step - loss: 0.7413 - acc: 0.8400\n",
      "Epoch 18/40\n",
      "100/100 [==============================] - 0s 371us/step - loss: 0.7238 - acc: 0.8600\n",
      "Epoch 19/40\n",
      "100/100 [==============================] - 0s 400us/step - loss: 0.7056 - acc: 0.8500\n",
      "Epoch 20/40\n",
      "100/100 [==============================] - 0s 157us/step - loss: 0.6879 - acc: 0.8500\n",
      "Epoch 21/40\n",
      "100/100 [==============================] - 0s 162us/step - loss: 0.6710 - acc: 0.8600\n",
      "Epoch 22/40\n",
      "100/100 [==============================] - 0s 155us/step - loss: 0.6550 - acc: 0.8500\n",
      "Epoch 23/40\n",
      "100/100 [==============================] - 0s 155us/step - loss: 0.6396 - acc: 0.8700\n",
      "Epoch 24/40\n",
      "100/100 [==============================] - 0s 153us/step - loss: 0.6255 - acc: 0.8500\n",
      "Epoch 25/40\n",
      "100/100 [==============================] - 0s 216us/step - loss: 0.6107 - acc: 0.8700\n",
      "Epoch 26/40\n",
      "100/100 [==============================] - 0s 254us/step - loss: 0.5968 - acc: 0.8800\n",
      "Epoch 27/40\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.5838 - acc: 0.8800\n",
      "Epoch 28/40\n",
      "100/100 [==============================] - 0s 292us/step - loss: 0.5708 - acc: 0.8700\n",
      "Epoch 29/40\n",
      "100/100 [==============================] - 0s 248us/step - loss: 0.5591 - acc: 0.8700\n",
      "Epoch 30/40\n",
      "100/100 [==============================] - 0s 309us/step - loss: 0.5472 - acc: 0.8700\n",
      "Epoch 31/40\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.5370 - acc: 0.8700\n",
      "Epoch 32/40\n",
      "100/100 [==============================] - 0s 360us/step - loss: 0.5259 - acc: 0.8700\n",
      "Epoch 33/40\n",
      "100/100 [==============================] - 0s 251us/step - loss: 0.5159 - acc: 0.8700\n",
      "Epoch 34/40\n",
      "100/100 [==============================] - 0s 379us/step - loss: 0.5065 - acc: 0.8700\n",
      "Epoch 35/40\n",
      "100/100 [==============================] - 0s 287us/step - loss: 0.4972 - acc: 0.8700\n",
      "Epoch 36/40\n",
      "100/100 [==============================] - 0s 264us/step - loss: 0.4882 - acc: 0.8700\n",
      "Epoch 37/40\n",
      "100/100 [==============================] - 0s 244us/step - loss: 0.4801 - acc: 0.8700\n",
      "Epoch 38/40\n",
      "100/100 [==============================] - 0s 355us/step - loss: 0.4717 - acc: 0.8700\n",
      "Epoch 39/40\n",
      "100/100 [==============================] - 0s 183us/step - loss: 0.4640 - acc: 0.8700\n",
      "Epoch 40/40\n",
      "100/100 [==============================] - 0s 264us/step - loss: 0.4570 - acc: 0.8700\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train, y_train, batch_size=8, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = history.history['acc']\n",
    "epochs = history.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, accs, c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 731us/step\n"
     ]
    }
   ],
   "source": [
    "evals = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.5192908501625061 Accuracy 0.8599999904632568\n"
     ]
    }
   ],
   "source": [
    "print('Loss', evals[0], 'Accuracy', evals[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "early = EarlyStopping(monitor='val_loss', min_delta=0, patience=4, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 70 samples, validate on 30 samples\n",
      "Epoch 1/40\n",
      "70/70 [==============================] - 0s 195us/step - loss: 0.4336 - acc: 0.8571 - val_loss: 0.4872 - val_acc: 0.9000\n",
      "Epoch 2/40\n",
      "70/70 [==============================] - 0s 250us/step - loss: 0.4289 - acc: 0.8571 - val_loss: 0.4826 - val_acc: 0.9000\n",
      "Epoch 3/40\n",
      "70/70 [==============================] - 0s 493us/step - loss: 0.4243 - acc: 0.8571 - val_loss: 0.4794 - val_acc: 0.9000\n",
      "Epoch 4/40\n",
      "70/70 [==============================] - 0s 300us/step - loss: 0.4196 - acc: 0.8714 - val_loss: 0.4757 - val_acc: 0.9000\n",
      "Epoch 5/40\n",
      "70/70 [==============================] - 0s 282us/step - loss: 0.4162 - acc: 0.8857 - val_loss: 0.4730 - val_acc: 0.9000\n",
      "Epoch 6/40\n",
      "70/70 [==============================] - 0s 286us/step - loss: 0.4112 - acc: 0.8714 - val_loss: 0.4688 - val_acc: 0.9000\n",
      "Epoch 7/40\n",
      "70/70 [==============================] - 0s 352us/step - loss: 0.4071 - acc: 0.8714 - val_loss: 0.4649 - val_acc: 0.9000\n",
      "Epoch 8/40\n",
      "70/70 [==============================] - 0s 225us/step - loss: 0.4031 - acc: 0.8857 - val_loss: 0.4619 - val_acc: 0.9000\n",
      "Epoch 9/40\n",
      "70/70 [==============================] - 0s 164us/step - loss: 0.3998 - acc: 0.8857 - val_loss: 0.4596 - val_acc: 0.9000\n",
      "Epoch 10/40\n",
      "70/70 [==============================] - 0s 286us/step - loss: 0.3959 - acc: 0.8857 - val_loss: 0.4557 - val_acc: 0.9000\n",
      "Epoch 11/40\n",
      "70/70 [==============================] - 0s 292us/step - loss: 0.3926 - acc: 0.8857 - val_loss: 0.4510 - val_acc: 0.9000\n",
      "Epoch 12/40\n",
      "70/70 [==============================] - 0s 328us/step - loss: 0.3890 - acc: 0.8857 - val_loss: 0.4472 - val_acc: 0.9000\n",
      "Epoch 13/40\n",
      "70/70 [==============================] - 0s 346us/step - loss: 0.3858 - acc: 0.8857 - val_loss: 0.4438 - val_acc: 0.9000\n",
      "Epoch 14/40\n",
      "70/70 [==============================] - 0s 442us/step - loss: 0.3825 - acc: 0.8857 - val_loss: 0.4414 - val_acc: 0.9000\n",
      "Epoch 15/40\n",
      "70/70 [==============================] - 0s 269us/step - loss: 0.3803 - acc: 0.8857 - val_loss: 0.4365 - val_acc: 0.9000\n",
      "Epoch 16/40\n",
      "70/70 [==============================] - 0s 390us/step - loss: 0.3763 - acc: 0.8857 - val_loss: 0.4347 - val_acc: 0.9000\n",
      "Epoch 17/40\n",
      "70/70 [==============================] - 0s 296us/step - loss: 0.3733 - acc: 0.8857 - val_loss: 0.4312 - val_acc: 0.9000\n",
      "Epoch 18/40\n",
      "70/70 [==============================] - 0s 291us/step - loss: 0.3701 - acc: 0.8857 - val_loss: 0.4280 - val_acc: 0.9000\n",
      "Epoch 19/40\n",
      "70/70 [==============================] - 0s 314us/step - loss: 0.3677 - acc: 0.8857 - val_loss: 0.4258 - val_acc: 0.9000\n",
      "Epoch 20/40\n",
      "70/70 [==============================] - 0s 417us/step - loss: 0.3645 - acc: 0.8857 - val_loss: 0.4209 - val_acc: 0.9000\n",
      "Epoch 21/40\n",
      "70/70 [==============================] - 0s 325us/step - loss: 0.3618 - acc: 0.8857 - val_loss: 0.4184 - val_acc: 0.9000\n",
      "Epoch 22/40\n",
      "70/70 [==============================] - 0s 395us/step - loss: 0.3589 - acc: 0.8857 - val_loss: 0.4142 - val_acc: 0.9000\n",
      "Epoch 23/40\n",
      "70/70 [==============================] - 0s 410us/step - loss: 0.3564 - acc: 0.8857 - val_loss: 0.4102 - val_acc: 0.9000\n",
      "Epoch 24/40\n",
      "70/70 [==============================] - 0s 325us/step - loss: 0.3538 - acc: 0.8857 - val_loss: 0.4068 - val_acc: 0.9000\n",
      "Epoch 25/40\n",
      "70/70 [==============================] - 0s 350us/step - loss: 0.3510 - acc: 0.8857 - val_loss: 0.4050 - val_acc: 0.9000\n",
      "Epoch 26/40\n",
      "70/70 [==============================] - 0s 271us/step - loss: 0.3488 - acc: 0.8857 - val_loss: 0.4020 - val_acc: 0.9000\n",
      "Epoch 27/40\n",
      "70/70 [==============================] - 0s 438us/step - loss: 0.3463 - acc: 0.8857 - val_loss: 0.3993 - val_acc: 0.9000\n",
      "Epoch 28/40\n",
      "70/70 [==============================] - 0s 318us/step - loss: 0.3441 - acc: 0.8857 - val_loss: 0.3976 - val_acc: 0.9000\n",
      "Epoch 29/40\n",
      "70/70 [==============================] - 0s 315us/step - loss: 0.3414 - acc: 0.8857 - val_loss: 0.3946 - val_acc: 0.9000\n",
      "Epoch 30/40\n",
      "70/70 [==============================] - 0s 256us/step - loss: 0.3392 - acc: 0.8857 - val_loss: 0.3929 - val_acc: 0.9000\n",
      "Epoch 31/40\n",
      "70/70 [==============================] - 0s 281us/step - loss: 0.3369 - acc: 0.8857 - val_loss: 0.3887 - val_acc: 0.9000\n",
      "Epoch 32/40\n",
      "70/70 [==============================] - 0s 348us/step - loss: 0.3347 - acc: 0.8857 - val_loss: 0.3863 - val_acc: 0.9000\n",
      "Epoch 33/40\n",
      "70/70 [==============================] - 0s 307us/step - loss: 0.3323 - acc: 0.8857 - val_loss: 0.3837 - val_acc: 0.9000\n",
      "Epoch 34/40\n",
      "70/70 [==============================] - 0s 328us/step - loss: 0.3306 - acc: 0.8857 - val_loss: 0.3800 - val_acc: 0.9000\n",
      "Epoch 35/40\n",
      "70/70 [==============================] - 0s 216us/step - loss: 0.3281 - acc: 0.8857 - val_loss: 0.3768 - val_acc: 0.9000\n",
      "Epoch 36/40\n",
      "70/70 [==============================] - 0s 283us/step - loss: 0.3259 - acc: 0.8857 - val_loss: 0.3737 - val_acc: 0.9000\n",
      "Epoch 37/40\n",
      "70/70 [==============================] - 0s 399us/step - loss: 0.3238 - acc: 0.8857 - val_loss: 0.3721 - val_acc: 0.9000\n",
      "Epoch 38/40\n",
      "70/70 [==============================] - 0s 271us/step - loss: 0.3216 - acc: 0.8857 - val_loss: 0.3696 - val_acc: 0.9000\n",
      "Epoch 39/40\n",
      "70/70 [==============================] - 0s 293us/step - loss: 0.3196 - acc: 0.8857 - val_loss: 0.3670 - val_acc: 0.9000\n",
      "Epoch 40/40\n",
      "70/70 [==============================] - 0s 425us/step - loss: 0.3178 - acc: 0.8857 - val_loss: 0.3639 - val_acc: 0.9000\n"
     ]
    }
   ],
   "source": [
    "history1 = model.fit(x_train, y_train, batch_size=8, epochs=40, validation_split=0.3, callbacks=[early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 127us/step\n"
     ]
    }
   ],
   "source": [
    "[loss, acc] = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4067875623703003\n",
      "Acc: 0.8799999904632568\n"
     ]
    }
   ],
   "source": [
    "print(f'Loss: {loss}')\n",
    "print(f'Acc: {acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
